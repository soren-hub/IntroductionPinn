{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da1f7df5",
   "metadata": {},
   "source": [
    "# Introducction to PINN's : First approximation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d81f74",
   "metadata": {},
   "source": [
    "Las redes neuronales (NN) tienen una gran capacidad predictiva sobre todo por su capacidad de encontrar relaciones no lineales entre los datos de entrada y salida, pero muchas veces para su aplicaci√≥n en ciencia su uso carece de interpretabilidad. En esencia las NN act√∫an como una caja negra, en donde las relaciones que desarrolla en la fase de entrenamiento son dif√≠ciles(por no decir imposible)de entender por los humanos.\n",
    "\n",
    "Una posible soluci√≥n para el problema anterior es agregar un t√©rmino extra a la funci√≥n de error, a este t√©rmino lo denominaremos \"regularizaci√≥n f√≠sica\" y principalmente act√∫a como una regularizaci√≥n. Como es sabido las regularizaciones sirven para evitar el sobre ajuste y mejorar la capacidad de generalizaci√≥n de la NN. Dos de las regularizaciones m√°s usuales son la Lazzo (L1) y Ridge (L1). Ambas regularizaciones consideran t√©rmino  ùúÜ  multiplicado por el t√©rmino regularizador, para un mismo  ùúÜ  la regularizaci√≥n L1, para la actualizaci√≥n de los pesos, considera en menor medida los outliers, en otras palabras le da m√°s importancia a los valores que tengan menor varianza. Por otro lado, la regularizaci√≥n L2, de manera contraria a la L1, considera en mayor medida los outliers.\n",
    "\n",
    "Teniendo en mente la idea de regularizaci√≥n y considerando un contexto donde se tenga datos que represente alg√∫n fen√≥meno f√≠sico del cual se tenga conocimiento a priori, es valido preguntarse ¬øes posible agregar alg√∫n t√©rmino de penalizaci√≥n que priorice las soluciones f√≠sicamente posible, y as√≠ ayude a la red a una mejor generalizaci√≥n? Bueno, como es de esperarse esta pregunta ya fue respondida por los autores del paper ‚ÄúPhysics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations‚Äù en el cual aplican el enfoque antes explicado y demuestran cu√°l es el t√©rmino que ayuda a la red neuronal a respetar las leyes de la f√≠sica subyacen al fen√≥meno que se est√° estudiando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff506d",
   "metadata": {},
   "source": [
    "# A bit of context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23287da5",
   "metadata": {},
   "source": [
    "En la investigaci√≥n antes expuesta se presentan las redes neuronales restringidas f√≠sicamente: redes neuronales que son entrenadas para resolver tareas de aprendizaje supervisado respetando cualquier ley f√≠sica que este dentro de la ecuaci√≥n diferencial que describe la din√°mica del sistema estudiado.\n",
    "\n",
    "Los autores presentan dos tipos de problemas que se pueden resolver mediante este enfoque.\n",
    "\n",
    "* Inferir la soluci√≥n para PDE's.  \n",
    "* Descubrimiento de PDE's. \n",
    "\n",
    "Las redes neuronales resultantes forman una nueva clase de aproximadores de funciones universales eficientes en datos que codifican naturalmente cualquier ley f√≠sica subyacente como informaci√≥n previa [1]. \n",
    "\n",
    "En este documento tomar√© como ejemplo el oscilador arm√≥nico amortiguado, ya que al tener una soluci√≥n exacta me posibilitara la comparaci√≥n de resultados para distintos enfoques. Principalmente, comparar√© el error y tiempo de c√≥mputo de los siguientes enfoques: \n",
    "\n",
    "* T√©cnicas tradicionales para resolver ecuaciones diferenciales.\n",
    "* Red neuronal sin restricciones f√≠sicas. \n",
    "* PINN. \n",
    " \n",
    "Y finalmente, aplicar√© una PINN para encontrar los par√°metros de la ecuaci√≥n diferencial del oscilador arm√≥nico amortiguado. \n",
    "\n",
    "Ante que todo, debo agradecer a Ben Moseley por su blog: [So, what is a physics-informed neural network?](https://benmoseley.blog/my-research/so-what-is-a-physics-informed-neural-network/)  en donde obtuve la mayor parte de la informaci√≥n para la elaboraci√≥n de este documento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da987f0",
   "metadata": {},
   "source": [
    "# Traditional approach to solve differential equation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23b56c",
   "metadata": {},
   "source": [
    "* taylor \n",
    "* runge kutta\n",
    "* multiples pasos \n",
    "* ... (compare stability (?))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533e520",
   "metadata": {},
   "source": [
    "# take a simple example: harmonic oscillator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6674b",
   "metadata": {},
   "source": [
    "# generator data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eaafa1",
   "metadata": {},
   "source": [
    "# apply traditional methods \n",
    "\n",
    "* **do this mainly to measure execution times**\n",
    "\n",
    "* **measure error, interpolation and inference**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452d813",
   "metadata": {},
   "source": [
    "# NN aproach to interpolate data \n",
    "\n",
    "overffiting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa2733",
   "metadata": {},
   "source": [
    "# PINN approach solve "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f33d3",
   "metadata": {},
   "source": [
    "- make train and test set \n",
    "- define arquitecture \n",
    "- define optimizer \n",
    "\n",
    "compare error and time with traditional methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e80da7",
   "metadata": {},
   "source": [
    "# PINN approach discovery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba66e6",
   "metadata": {},
   "source": [
    "# Define funtion for graph train of neural networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229deb0a",
   "metadata": {},
   "source": [
    "# Conclusion \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b608ad40",
   "metadata": {},
   "source": [
    "# Referencias: \n",
    "\n",
    "[1] Raissi, M., Perdikaris, P. y Karniadakis, GE (2019). Redes neuronales informadas por la f√≠sica: un marco de aprendizaje profundo para resolver problemas directos e inversos que involucran ecuaciones diferenciales parciales no lineales . Revista de F√≠sica Computacional.\n",
    "\n",
    "[2] Problema de f√≠sica inspirado en esta publicaci√≥n de blog: https://beltoforion.de/en/harmonic_oscillator/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03d20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
